install.packages("paco")
install.packages("ggedit")
library(MASS)
library(rpart)
library(RevoScaleR)
connStr <- "Driver=SQL Server;Server=BryanCafferkyPC\\SS2016;Database=RSQL_Walkthrough;Uid=bryan;Pwd=bryan"
qlShareDir <- paste("C:\\AllShare\\",Sys.getenv("USERNAME"),sep="")
sqlWait <- TRUE
sqlConsoleOutput <- FALSE
cc <- RxInSqlServer(connectionString = connStr, shareDir = sqlShareDir,
wait = sqlWait, consoleOutput = sqlConsoleOutput)
r
sqlShareDir <- paste("C:\\AllShare\\",Sys.getenv("USERNAME"),sep="")
sqlWait <- TRUE
sqlConsoleOutput <- FALSE
cc <- RxInSqlServer(connectionString = connStr, shareDir = sqlShareDir,
wait = sqlWait, consoleOutput = sqlConsoleOutput)
rxSetComputeContext(cc)
sqlShareDir <- paste("C:\\AllShare\\",Sys.getenv("USERNAME"),sep="")
sqlWait <- TRUE
sqlConsoleOutput <- FALSE
cc <- RxInSqlServer(connectionString = connStr, shareDir = sqlShareDir,
wait = sqlWait, consoleOutput = sqlConsoleOutput)
library(RevoScaleR)
library(RevoScaleR)
sqlShareDir <- paste("C:\\AllShare\\",Sys.getenv("USERNAME"),sep="")
sqlWait <- TRUE
sqlConsoleOutput <- FALSE
cc <- RxInSqlServer(connectionString = connStr, shareDir = sqlShareDir,
wait = sqlWait, consoleOutput = sqlConsoleOutput)
rxSetComputeContext(cc)
connStr
sampleDataQuery <- "select top 1000 tipped, fare_amount, passenger_count,trip_time_in_secs,trip_distance,
pickup_datetime, dropoff_datetime, pickup_longitude, pickup_latitude, dropoff_longitude,
dropoff_latitude from nyctaxi_sample"
inDataSource <- RxSqlServerData(sqlQuery = sampleDataQuery, connectionString = connStr,
colClasses = c(pickup_longitude = "numeric", pickup_latitude = "numeric",
dropoff_longitude = "numeric", dropoff_latitude = "numeric"),
rowsPerRead=500)
rxGetVarInfo(data = inDataSource)
inDataSource
install.packages(Rtts)
install.packages("Rtts")
library('Rtts')
tts_google("Hello.")
text <- "hello."
# Using default setting: speed=0, volume=100, speaker="Bruce".
tts_ITRI_getID(text, speed=0, volume=100, speaker="Bruce")
tts_ITRI_getStatus
tts_ITRI_getStatus
getwd()
targetfile <- "D:/Users/Bryan/Documents/GitHub/Professional/Documents/Presentations/R_DataScience_AtoZ"
text <- "hello."
# Using default setting: speed=0, volume=100, speaker="Bruce".
tts_ITRI_getID(text, speed=0,
volume=100,
speaker="Bruce",
destfile = targetfile)
tts_ITRI_getStatus
targetfile <- "D:/Users/Bryan/Documents/GitHub/Professional/Documents/Presentations/R_DataScience_AtoZ/hello.wav"
text <- "hello."
# Using default setting: speed=0, volume=100, speaker="Bruce".
tts_ITRI_getID(text, speed=0,
volume=100,
speaker="Bruce",
destfile = targetfile)
tts_ITRI_getStatus
tts_google("Hello.")
tts_google("Hello.", destfile = targetfile)
setwd("D:/Users/Bryan/Documents/GitHub/Professional/Documents/Presentations/R_DataScience_AtoZ/hello.wav")
setwd("D:/Users/Bryan/Documents/GitHub/Professional/Documents/Presentations/R_DataScience_AtoZ")
tts_google("Good morning Bryan!")
excel <- comGetObject("Excel.Application")
system('powershell -command "gci -r|sort Length -desc|select fullname -f 5"')
system('powershell -command "import-module umd_module; Out-udfSpeech "Good morning Bryan" ')
system('powershell -command "import-module umd_module; Invoke-udfSpeech "Good morning Bryan" ')
system('powershell -command "Import-Module umd_module; Out-udfSpeech "Hello"')
dir
Get-ChildItem
install.packages("RDCOMClient")
library("RDCOMClient")
voice1 <- COMCreate("SAPI.SpVoice")
voice1.Speak("Hello Bryan",1)
voice1$Speak("Hello Bryan",1)
speech <- "The R programming language is cool"
# $speaker.Speak($speakit, 1 )
voice1$Speak(speech,1)
speech <- "The R programming language is
a popular data science language
that excels in statistics.  R
does the work for you.  "
# $speaker.Speak($speakit, 1 )
voice1$Speak(speech,1)
speech <- "The R programming language is
a popular data science language
that excels in statistics.  R
does the work for you.  "
# $speaker.Speak($speakit, 1 )
voice1$Speak(speech,1)
speech <- "The R programming language is
a popular data science language that excels in statistics.
R does the work for you. It features data manipulation,
machine learning, and amazing visualizations.
Lets get going!!!"
# $speaker.Speak($speakit, 1 )
voice1$Speak(speech,1)
source('D:/Users/Bryan/Documents/GitHub/shared/shared/DataScienceFromAtoZ/scr_opening_speech.R', echo=TRUE)
a <- 55
plot(cars)
a <- 55
plot(cars)
hist(1:20)
a <- 55
hist(1:20)
a <- 55
hist(mtcars$cyl)
knitr::opts_chunk$set(echo = FALSE)
summary(cars)
shiny::runApp('D:/DocumentsD/R/shiny2/Bryan1')
v <- 5
v
rnorm(15)
v1 <- rnorm(15)  # Note the <- instead of =
v1
1:5
v2 <- 1:5
v2
v1
v2
v3 <- c(v1,v2)  # Casts to compatible type.  Be careful on this!
v3
myvect <- c(1,2,3,4,5)
myvect
mean(myvect)
sum(myvect)
summary(myvect)
sd(myvect)
myvect * 2
cat("The mean of your vector is = ", mean(myvect))
myv2 <- c("A","B","C","D")  # String vector...
myv2
mymat = matrix(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15),nrow=3)
mymat
colnames(mymat) <- c("First","Second","Third", "Fourth", "Five")
mymat
mymat[Second]
mymat['Second']
mymat[,'Second']
mymat[2,3]
mymat[,3]
mymat[3,]
class(mymat[,3])
class(mymat)
class(mymat[,3])
mymat[c(2,3),]
class(mymat)
mymat[c(2,3),]
as.matrix(mymat[,3])
mymat / 2
mymat <- matrix(c(mymat, 16, 17, 18),nrow=3)
mymat
myv2 <- c("A","B","C","D")  # String vector...
myv2
mylist <- list(mymat,myv2)
mylist
class(mylist)
mylist * 2
mylist[[1]] * 2
v1 <- c(1,2,3,4,5,6)
v2 <- c(6,5,4,3,2,1)
v3 <- c(1,8)
v1 + v2
v3 + v1
v1 > v2
v1[FALSE]
v1[TRUE]
v1[c(TRUE,FALSE,TRUE,FALSE,TRUE,FALSE)]
v1 > v2
v1[v1 > v2]
v1[v1 > v3]
myvect <- 1:10
myvect
myvect > 3
myvect[myvect > 3]
myvect > 3
myvectbool <- myvect > 3
myvectbool
yourvect <- 20:30
yourvect
yourvect[myvectbool]
yourvect[myvectbool==FALSE]
yourvect[yourvect > 22]
mymat = matrix(1:32,nrow=8)
mymat
v1 = mymat[,2]
v1
mymat[,2] >10
b1 <- mymat[,2] >10
b1
v1
mymat[mymat[,2] >10,]
mymat[mymat[,2] >10,]
colnames(mymat) <- c("First","Second","Third","Fourth")
mylist <- list(cars,salesdata)
mylist  # A collection of objects.
cars
Square <- function(x) {
return(x^2)
}
myvect = 1:5
Square(myvect)
var <- matrix(1:20, ncol = 4)
var
apply(var,2,sum)
apply(var,1,sum)
mylist = list(1,5,6,7)
lapply(mylist, mean)
mylist
mylist = list(1:5,5,6,7)
mylist
lapply(mylist, mean)
mylist = list(1:5,5:20,1:6,7:12)
lapply(mylist, mean)
mylist/2
mean(mylist)
lapply(mylist, mean)
mean(mylist[])
mean(mylist[,])
x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))
# compute the list mean for each list element
lapply(x, mean)
lapply(x, quantile, probs = 1:3/4)
sapply(x, quantile)
lapply(x, quantile, probs = 1:3/4)
sapply(x, quantile)
i39 <- sapply(3:9, seq) # list of vectors
sapply(i39, fivenum)
lapply(x, quantile, probs = 1:3/4)
x
sapply(x, quantile)
sapply(mylist, sum)
x
sapply(x, quantile)  # returns a matrix
sapply(x, quantile)  # returns a matrix
i39 <- sapply(3:9, seq) # list of vectors
sapply(i39, fivenum)
i39 <- sapply(3:9, seq)
i39
vapply(i39, fivenum,
c(Min. = 0, "1st Qu." = 0, Median = 0, "3rd Qu." = 0, Max. = 0))
apply(var,2,sum) # sum columns
vapply(i39, fivenum,
c(Min. = 0, "1st Qu." = 0, Median = 0, "3rd Qu." = 0, Max. = 0))
i39 <- sapply(3:9, seq) # list of vectors
vapply(i39, fivenum,
c(Min. = 0, "1st Qu." = 0, Median = 0, "3rd Qu." = 0, Max. = 0))
sapply(i39, fivenum)
fivenum
seq
i39
lapply(1:30, sum)
lapply(1:30, quantile, probs = 1:3/4)
var <- matrix(1:20, ncol = 4)
apply(var,2,sum) # sum columns
mylist = list(1:5,5:20,1:6,7:12)
mean(mylist)
# But this does...
lapply(mylist, mean)
installed.packages()
packagelist <- installed.packages()
View(packagelist)
install.packages("dplyr")
library("dplyr")
mtcars
mtcarssubset <- select(mtcars, mpg, disp)
head(mtcarssubset)
browseVignettes(package="dplyr")
packageDescription("dplyr")
install.packages("devtools")
help(package = "babynames")
library("babynames")
help(package = "babynames")
head(babynames)
library("babynames")
library(devtools)
install_github("hadley/babynames")
library("babynames")
help.start()  # Get help index
h
help(package = "babynames")
head(babynames)
tail(babynames)
require("dplyr")
str(iris)
select(iris, Sepal.Length:Petal.Length)
iris_df <- select(iris, Species, Sepal.Length, Sepal.Width)
iris_df
head(mutate(iris_df, NewSepalLength = Sepal.Length / 10 ) )
summarise(iris, mean_petal_length = mean(Petal.Length, na.rm = TRUE))
select(
arrange(
mutate(iris,
petal_2_sepal_length = Petal.Length / Sepal.Length),
desc(petal_2_sepal_length)),
Species, petal_2_sepal_length)
iris %>%
mutate(petal_2_sepal_length = Petal.Length / Sepal.Length) %>%
arrange(desc(petal_2_sepal_length)) %>%
select(Species, petal_2_sepal_length)
library("ggplot2")
ggplot(iris, aes(x = factor(""), fill = Species) ) +
geom_bar()
ggplot(iris,
aes(x = factor(""), fill = Species) ) +
geom_bar() +
coord_polar(theta = "y") +
scale_x_discrete("")
ggplot(iris,
aes(x = factor(""), fill = Species) ) +
geom_bar() +
coord_polar(theta = "y") +
scale_x_discrete("") +
labs(title = "Iris by Species")
library(psych)
describe(mtcars$wt)  # For one column
describe(mtcars)     # For all columns
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
v <- c(2,1,2,3,1,2,3,4,1,5,5,3,2,3)
result <- getmode(v)
print(result)
boxplot(mtcars$wt, main = 'Mtcars Weight Boxplot', col='lightblue')
hist(Nile)   # close to normal distribution
hist(ChickWeight$weight, col='magenta')  # Skews to left
EUSales <- rnorm(NumberOfValues, mean = 500)
hist(EUSales)
NumberOfValues <- 1000
EUSales <- rnorm(NumberOfValues, mean = 500)
hist(EUSales)
hist(EUSales, col = 'lightgreen')
USSales <- rnorm(NumberOfValues, mean = 2000)
hist(USSales, col = 'magenta')
avg_eu <- sum(EUSales)/NumberOfValues
avg_us <- sum(USSales)/NumberOfValues
avg_eu
avg_us
# 1 - Find the mean...
avg_eu <- sum(EUSales)/NumberOfValues
avg_us <- sum(USSales)/NumberOfValues
avg_eu
avg_us
# 2 - Find the difference from the mean of each value
#     and square it...
diff_eu <- (EUSales - avg_eu)^2
diff_eu
diff_us <- (USSales - avg_us)^2
diff_us
# 3 - Add up the values from step 2...
diff_tot_eu <- sum(diff_eu)
diff_tot_eu
diff_tot_us <- sum(diff_us)
diff_tot_us
# 4 - Divide the total from step 3 by the number of values...
diff_avg_eu <- diff_tot_eu / NumberOfValues  # variance
diff_avg_eu
diff_avg_us <- diff_tot_us / NumberOfValues  # variance
diff_avg_us
# 5 - Take the square root of the result of step 4...
sd_eu <- sqrt(diff_avg_eu)  # standard deviation
sd_us <- sqrt(diff_avg_us)  # standard deviation
sd_eu
sd_us
# New sales figures come in.
# Who had the larger sales growth over average?
NewEUSales <- 502
NewUSSales <- 2002
# Convert each amount to standard units...
(NewEUSales - avg_eu)/sd_eu
(NewUSSales - avg_us)/sd_us
summary(mtcars$wt)
boxplot(mtcars$wt, col =  'lightblue')
library(psych)
describe(mtcars$wt)  # For one column
describe(mtcars)     # For all columns
boxplot(mtcars$wt, main = 'Mtcars Weight Boxplot', col='lightblue')
hist(Nile)   # close to normal distribution
hist(ChickWeight$weight, col='magenta')  # Skews to left
summary(mtcars$wt)
boxplot(mtcars$wt, col =  'lightblue')
library(psych)
describe(mtcars$wt)  # For one column
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
v <- c(2,1,2,3,1,2,3,4,1,5,5,3,2,3)
result <- getmode(v)
print(result)
x <- 1:20
Mode(x, na.rm = FALSE)
dir
this.dir <- dirname(parent.frame(2)$ofile)
setwd(this.dir)
dirname(parent.frame(2)$ofile)
source('~/.active-rstudio-document', echo=TRUE)
getwd()
setwd(this.dir)
getwd()
$ofile
setwd("D:/Users/Bryan/Documents/GitHub/Professional/Documents/Presentations/R_DataScience_AtoZ/Script/Part_3")
datapath <- paste0(Sys.getenv("HOME"), "/IntroductionToR/Data")
salesdata <- read.csv("sales.csv",header=T,sep=",",stringsAsFactors = FALSE)
salesdata
class(salesdata)
salesdata <- read.csv("sales.csv",header=T,sep=",", stringsAsFactors = FALSE)
salesdata
salesdata[SalesPersonID == 6, 'TotalSales'] <- 2000
salesdata[SalesPersonID == 6, 'TotalSales']
salesdata <- read.csv("sales.csv",header=T,sep=",", stringsAsFactors = FALSE)
salesdata
salesdata[SalesPersonID == 6, 'TotalSales']
salesdata
salesdata[SalesPersonID == 6, 'TotalSales']
salesdata['SalesPersonID' == 6, 'TotalSales']
salesdata['SalesPersonID' == 6, 'TotalSales']
salesdata <- read.csv("sales.csv",header=T,sep=",",stringsAsFactors = FALSE)
salesdata
class(salesdata)
str(salesdata)
# Just show the first few rows...
head(salesdata)
tail(salesdata)
dim(salesdata)
summary(salesdata$TotalSales)
plot(salesdata$TotalSales)
hist(salesdata$TotalSales)
hist(salesdata$TotalSales, col = 'blue')
salesdata["TotalSales"]
salesdata[1]
class(salesdata["TotalSales"])
salesdata[,"TotalSales"]
salesdata[c("LastName", "TotalSales")]
class(salesdata[c("LastName", "TotalSales")])
salesdata[,2]
salesdata[1:3,]
class(salesdata[1:3,])
salesdata[salesdata$TotalSales > 120,]
salesdata <- read.csv("sales_noheadings.csv",header=F,sep=",", stringsAsFactors = FALSE)
salesdata
names(salesdata) <- c('SalesPersonID','FirstName', 'LastName', 'TotalSales', 'AsOfDate', 'SentDate', 'EmployeeID')
salesdata
rownames(salesdata) <- salesdata$EmployeeID
salesdata
salesdata['108',]
attach(salesdata)
TotalSales
mean(TotalSales)
search()
salesdata <- read.csv("sales.csv",header=T,sep=",", stringsAsFactors = FALSE)
salesdata
salesdata[SalesPersonID == 6, 'TotalSales'] <- 2000
salesdata[SalesPersonID == 6, 'TotalSales']
salesdata$TaxAmount = salesdata$TotalSales * .07  # 7 % tax rate
salesdata
salesdata$TaxAmount = NULL
salesdata
salesdata <- rbind(salesdata, list(30, 'Sal', 'Amanda', 3000, '3/27/2014', '7/8/2014'))
salesdata
salesdata[-6,]
salesdata[order(salesdata$LastName, salesdata$FirstName),]
salesdata[with(salesdata, order(LastName, FirstName)), ]
library(MASS)
library(rpart)
help(birthwt)  # brings up documentation.
str(birthwt)   # see the column details.
head(birthwt)  # view first few rows.
hist(birthwt$bwt, col='blue')  # Histogram
table(birthwt$low)
attach(birthwt)
bw_subset <- subset(birthwt, select = c(age,lwt) )
boxplot(bw_subset,col=c("blue","red"),ylab="Centimeters")
library(psych)
pairs.panels(birthwt[,c('age','lwt','race','smoke','low')])
cols <- c('low', 'race', 'smoke', 'ht', 'ui')
birthwt[cols] <- lapply(birthwt[cols], as.factor)
set.seed(1)
train <- sample(1:nrow(birthwt), 0.75 * nrow(birthwt))
test = birthwt[-train, ]
library(rpart)
birthwtTree <- rpart(low ~ . - bwt, data = birthwt[train, ],
method = 'class')
#
library(rattle)
fancyRpartPlot(birthwtTree, main="Birth Weight")
summary(birthwtTree)
birthwtPred <- predict(birthwtTree, test, type = 'class')
library(gmodels)
CrossTable(x = test$low, y =  birthwtPred, prop.chisq=FALSE)
library("ROCR")
pred <- prediction(birthwtTree, test$low)
library(class)
trainLabels <- birthwt[train, 1]
testLabels <- birthwt[-train, 1]
newdata <- birthwt[-train,c('age','lwt','race','smoke','ptl','ht','ui','ftv')]
write.csv(newdata, file = 'newbwdata.csv')
birthwt_pred2 <- knn(train = birthwt[train, ], test = birthwt[-train, ], cl = trainLabels, k=2)
birthwt_pred2
library(gmodels)
CrossTable(x = testLabels, y = birthwt_pred2, prop.chisq=FALSE)
newdata
